# Exploratory Data Analysis 

```{python}
#| echo: false
#| warning: false 

### Importing require libraries 
import plotly.graph_objects as go
import plotly.express as px
import pandas as pd
import numpy as np
import datetime

from IPython.display import display, Markdown
from IPython.display import Image

```
 
## Preprocessing and Data Dictionary 

We assessed the basic specifications of the dataset, removed duplicates and anomalies and dropped undesired columns to finally get <b>170,144</b> submissions and <b>18,548,934</b> comments in the respective datasets. The variables of interest after preprocessing the datasets are listed below: 

In the <b> Submissions </b> dataset :  
<ul> 
    <li> <b>author</b> : The user who created the post. </li>
    <li> <b>created_utc</b> : The time the submission or comment was posted. Was used in the time series analysis section of our project. </li>
    <li> <b>domain</b> : The news site posted in the submission. </li> 
    <li> <b>id </b>: The unique identifier of each post. </li> 
    <li> <b>num_comments</b> : The number of comments under each submission. This may not capture the exact picture as it is dependent on the day the data was retrieved. </li> 
    <li> <b>url </b>: The url associated with the post. Most of the submissions contain this url to the news article. </li> 
    <li> <b>score </b>: The Karma score awarded to each post </li> 
</ul>

In the <b> Comments </b> dataset :  
<ul> 
    <li> <b>author</b> : The user who posted the comment. </li>
    <li> <b>created_utc </b>: The time the submission or comment was posted. Was used in the time series analysis section of our project. </li>
    <li> <b>body</b> : The text in the comment. </li> 
    <li><b> id </b>: The unique identifier of each comment. </li> 
    <li> <b>link_id</b> : The id of the submission under which the comment exists. </li> 
    <li> <b>controversiality</b> : Whether a comment was classified as 'controversial'. </li> 
    <li><b> gilded </b>: Whether the comments have been gilded or awarded. </li> 
    <li><b> distinguished </b>: Whether the comments have been distinguished as moderator. </li> 
    <li><b> score</b> : The Karma score awarded to each post </li> 
</ul>   

During this process, several dummy variables were created to aid in our analysis. A <i>foreign key</i> like variable called <b>submission_id</b> was also created in the comments dataset, that linked any comment to the submission it was made under.  

<a id = "EDA1_DailyEngagement"> </a>

## Analyzing Weekly Activity Trends
In this section, we delve into understanding the patterns of user engagement on Reddit. We begin by examining the distribution of activity across different days of the week, extracted from the DateTime variable. By grouping the data based on these days, we quantify the frequency of user interactions, both in terms of comments and submissions. The insights derived from this analysis are visually represented through a bar graph in Figure 2.1 and Figure 2.2.


```{python}
#| echo: false
#| warning: false 

Image(filename="../data/plots/submissions_day.png")
```
<b> Figure 2.1: Number of submissions per day of the week from 2021-2023  </b> 
<br><br>
As shown in Figure 2.1, the trend for submissions exhibits a significant dip during the weekends. This suggests that users are less likely to initiate new threads or topics on Saturday and Sunday.A potential factor contributing to this weekend slump could be the downtime in news cycles, as journalists and news outlets typically slow down on these days.Interestingly, Thursday is the busiest day for submissions, contrary to the intuitive expectation that Monday would start the week with a surge.

```{python}
#| echo: false
#| warning: false 

Image(filename="../data/plots/day_of_week.png")
```
<b> Figure 2.2: Number of comments per day of the week from 2021-2023  </b> 
<br>
Figure 2.2 depicts a different dynamic for comments, with activity gradually increasing from Monday, reaching a zenith on Thursday. This progressive increase could indicate users' growing engagement with content as the week unfolds. Despite both submissions and comments peaking on Thursday, only comments display a steady climb throughout the weekdays.
<br><br>
When we synthesize the data from submissions and comments, a compelling narrative about user engagement emerges. Thursday stands out as a pinnacle of activity for Reddit, with both submissions and comments reaching their highest levels. This indicates that Thursdays are not just about new content being created but also about the peak in interactions with existing threads. The pattern across the week shows more engagement with ongoing discussions rather than starting new ones, especially as the week progresses.

<a id = "EDA2_DifferencePosts"> </a>

## Analyzing Post Frequency by Year

In this analysis, we investigate the disparity in the number of posts across different years. Utilizing the DateTime variable, we extract the year component to group the data accordingly. The findings are presented in two separate tables: Table 2.1 for submissions and Table 2.2 for comments.

```{python}
#| echo: false
#| warning: false 
# Reading the CSV files into Pandas DataFrames
comments_per_year_df = pd.read_csv('../data/csv/comments_per_year.csv')
submissions_per_year_df = pd.read_csv('../data/csv/submissions_per_year.csv')
print(submissions_per_year_df.to_markdown(tablefmt = "fancy_outline", index = False))

```

<b> Table 2.1: Submissions Per Year </b> 
<br><br>

```{python}
#| echo: false
#| warning: false 

comments_per_year_df['count'] = comments_per_year_df['count'].apply(str)
print(comments_per_year_df.to_markdown(tablefmt = "fancy_outline", index = False))

```
<b> Table 2.2: Comments Per Year </b> 
<br><br>
The analysis of post frequency by year reveals intriguing trends. While there is a notable decline in submissions from 2021 to 2023, the number of comments exhibits a contrasting pattern, with a significant increase observed from 2021 to 2022 followed by a decline in 2023. This divergence suggests a potential shift in user behavior towards increased engagement with existing content rather than generating new posts. Further investigation into the underlying factors influencing this trend could provide valuable insights into evolving user preferences and platform dynamics.


<a id = "EDA3_FakeNews"> </a>
## Assessing Percentage of Comments with Fake News Indicators

To evaluate the prevalence of fake news indicators in comments, we employed regex to detect phrases such as "fake news," "bullshit," or "propaganda." Subsequently, a fake news indicator column was created to denote the presence of these phrases in comments. Grouping the data by this indicator column, we tallied the counts and visualized the findings in a chart. Among the total comments analyzed, 407,621 were flagged as containing fake news indicators, while the majority, comprising 49,562,279 comments, were deemed free from such indicators. This signifies that approximately 0.8% of comments were identified as potentially containing fake news elements. Further exploration into the context and implications of these comments could offer valuable insights into the dissemination of misinformation within online communities. 

```{python}
#| echo: false
#| warning: false 

Image(filename="../data/plots/misinformation.png")
```
<b> Figure 2.3: Comments containing Misinformation Indicators from 2021-2023  </b> 
<br><br>



<a id = "EDA4: Active Users"> </a>

## Analyzing User Activity 

As we delve into the dynamics of user interactions within the news-centric communities on Reddit, we encounter some intriguing patterns. The subreddit under examination boasts 31.5 million subscribers. However, a closer inspection reveals that in the past year, approximately 27,000 unique users have made submissions, and around 1.2 million have commented.

A minute fraction of these users contribute the bulk of the submissions, which is delineated in Figure 2.4. This chart illustrates a comparison of posting frequency among the top 10 users in both the News and World News subreddits. The disparity is stark; the top-ranked user alone is responsible for more than 60,000 submissions in the News subreddit, significantly overshadowing the rest.


```{python}
#| echo: false
#| warning: false 

# top_users_comparison
# data/plots/top_users_comparison.png
Image(filename="../data/plots/top_users_comparison.png")
```
<b> Figure 2.4: Top 10 Users Post Comparison for News and World News Subreddits </b> 
<br><br>
It was observed from the table above, that the most popular news sites on the subreddit over the past year were generally from western countries. This could potentially explain the high consumption of news related to the war within the subreddit despite the presence of Russian media sources as well. 

Live thread submissions were found and it was determined that all the live thread submissions pertained to the war. This provided an opportunity to evaluate the comments of the live thread against regular submissions that also dealt with the Conflict as shown in the table below.

<b> Table 2.3 : Comparison of Live Thread Comments and Regular Comments on War </b> 

```{python}
#| echo: false
#| warning: false 


```

The table above captures the percentage of comments that were controversial, gilded and distinguished for the live thread and for other submissions dealing with the war. It was observed that more controversiality was present in regular submissions as compared to live threads, possible due to larger number of normal posts.


<a id = "EDA5: News Sources"> </a>

## Most Common Words

Progressing with our analysis, we also looked at which were the most commonly used words or phrases in the comments of the top 3 news stories. To evaluate this we generated word clouds as shown below.

<h3> Figure 2.6 : Word Cloud Of Comments From Top 3 News Stories </h3> 

```{python}
#| echo: false
#| warning: false

import ipywidgets as widgets
import IPython.display as display
from IPython.display import HTML
## Read images from file 


```

These word clouds revealed that the Russia-Ukraine Conflict , and political leaders of these countries were the most repeated words. We also found terms relating to Queen Elizabeth II’s demise and the British royal family to be quite repetitive. 



## Comparison with Other Sources 

As a final task, we sought to compare the information present in the subreddit’s submissions about the events pertaining to Russia and Ukraine, with the events data from Armed Conflict Location & Event Data Project (ACLED). ACLED collects real-time data on locations, dates, actors, fatalities and types of all reported political violence and protest events around the world, from various international and regional news sources. The ACLED data for Ukraine and Russia were aggregated to obtain daily counts of event types in the following categories:
<ul>
<li><b>Armed Clashes</b></li>
<li><b>Shelling/Artillery/Missile Attacks</b></li>
<li><b>Remote Explosives/Landmines/IED</b></li>
<li><b>Disrupted Weapons Use</b></li>
</ul>
The submissions titles were analyzed using regex to find terms related to aforementioned event types to obtain daily counts for these events. The cosine similarity between ACLED counts and counts obtained from submissions for each event type were found as shown below in table 2.4. Our results indicate that reddit data is not quite similar to ACLED data. One possible reason for low similarity might be that our data has been filtered to English, and ACLED uses its own translation methodology and produces regional level news related to the conflict as well.  

<b> Table 2.4 : Cosine Similarity Scores for ACLED and Submissions Dataset on Different War Events </b> 

```{python}
#| echo: false
#| warning: false


```