[
  {
    "objectID": "appendix.html",
    "href": "appendix.html",
    "title": "Appendix",
    "section": "",
    "text": "Appendix"
  },
  {
    "objectID": "summary.html#about-the-team",
    "href": "summary.html#about-the-team",
    "title": "Introduction",
    "section": "About the Team",
    "text": "About the Team\n\nLucienne L. Julian      Sonali Subbu Rathinam   Peijin Li"
  },
  {
    "objectID": "goals.html",
    "href": "goals.html",
    "title": "Business Goals",
    "section": "",
    "text": "Business Goal -1 : Determine which day people use Reddit most frequently.\n\n Technical proposal:  To find this, we will extract the day from the DateTime variable. We will then group by the new day variable and count the group by data. We will create a bar graph of the counts to visualize the findings. This will be conducted for both comments and submissions.\n\n\n \n\n Business Goal - 2 : Determine which fake news identifier is used the most. \n\nTechnical Proposal : First, we will utilize regex to match on different fake news identifiers like bullshit, propaganda, or fake news. Using this, we will create a fake news indicator column that shows if the phrase was present in the comment. Then, we will group by the indicator column and count the groups. We will visualize our findings in a table.\n\n\n \n\n Business Goal - 3 : Determine the difference in the number of posts by year.\n\nTechnical proposal : We will extract the year from the DateTime variable. Using this, we will group by year and count the grouped data. We will visualize our findings in a table that includes comments and submissions.\n\n\n \n\nBusiness Goal - 4 : Who are those most active accounts in these news subreddits? \n\nTechnical Proposal : To determine the most active accounts in the news subreddits, we will identify the top 10 users with the highest number of posts. We will extract the usernames from the dataset and group by each user to count their posts. Then, we will compare the number of posts made by these top users in both subreddits. Finally, we will present the findings in a bar chart.\n\n\n \n\nBusiness Goal - 5 : Determine the frequency and the accumulated scores of news sources. \n\nTechnical Proposal:  In this analysis, our objective is to comprehend the frequency and cumulative scores associated with different news sources. Initially, we’ll extract the “domain” information from the URL of each post. Subsequently, we’ll aggregate the data based on these sources, computing both the frequency of posts and summarizing the scores attributed to each source.\n\n\n \n\n\n\n\n\nBusiness Goal - 6 : Determine the news topics that are interacted with the most.  Among all types of news, which category do people concern about the most? Is it related to war, disaster, food crisis or something else? \n\nTechnical Proposal: Use topic modeling to create different broad news categories. Group by those categories and analyze the comments.\n\n\n \n\nBusiness Goal - 7 : \nDetermine what topics are perceived as fake news. \n\nTechnical Proposal : Use topic modeling created above. Perform sentiment analysis on the comments. Comments with negative sentiment and containing misinformation identifiers will be misinformation. Topics with more of these comments will be perceived as fake news.\n\n\n \n\nBusiness Goal - 8 : \nFind this difference in perceived misinformation from 2021 (post-election year) to 2023 (pre-election year). \n\nTechnical Proposal : We will use the combined sentiment analysis and misinformation indicator to identify comments with negative sentiment and contain a misinformation indicator. We will group by this new variable and count the grouped data. Since there are significantly fewer comments in 2023, we will then take the rate of misinformation comments to compare the two.\n\n\n \n\n\n\n\nBusiness Goal - 9 : \nWhich articles might be perceived as misinformation, or labeled by users as fake news? \n\nTechnical Proposal : We will employ a supervised machine learning model to predict articles that are prone to be perceived as misinformation. Specifically, we’ll utilize techniques such as decision trees to discern which features contribute significantly to the classification process. By analyzing various attributes of article titles, we’ll determine patterns indicating potential fake news. This comprehensive approach will shed light on both the types of titles more likely to be labeled as fake news and the key features crucial for classification accuracy.\n\n\n \n\nBusiness Goal - 10 : \nAmong political topics, is there any correlation? Are certain topics mentioned together more frequently than others?\n\nTechnical Proposal : We will conduct a network analysis to explore the relationships between different political topics. This analysis will help us understand the connections and interactions among various political themes, providing insights into how they are interconnected or influence each other within the broader political landscape.",
    "crumbs": [
      "I. Overview",
      "Business Goals"
    ]
  },
  {
    "objectID": "goals.html#exploratory-data-analysis-goals",
    "href": "goals.html#exploratory-data-analysis-goals",
    "title": "Business Goals",
    "section": "",
    "text": "Business Goal -1 : Determine which day people use Reddit most frequently.\n\n Technical proposal:  To find this, we will extract the day from the DateTime variable. We will then group by the new day variable and count the group by data. We will create a bar graph of the counts to visualize the findings. This will be conducted for both comments and submissions.\n\n\n \n\n Business Goal - 2 : Determine which fake news identifier is used the most. \n\nTechnical Proposal : First, we will utilize regex to match on different fake news identifiers like bullshit, propaganda, or fake news. Using this, we will create a fake news indicator column that shows if the phrase was present in the comment. Then, we will group by the indicator column and count the groups. We will visualize our findings in a table.\n\n\n \n\n Business Goal - 3 : Determine the difference in the number of posts by year.\n\nTechnical proposal : We will extract the year from the DateTime variable. Using this, we will group by year and count the grouped data. We will visualize our findings in a table that includes comments and submissions.\n\n\n \n\nBusiness Goal - 4 : Who are those most active accounts in these news subreddits? \n\nTechnical Proposal : To determine the most active accounts in the news subreddits, we will identify the top 10 users with the highest number of posts. We will extract the usernames from the dataset and group by each user to count their posts. Then, we will compare the number of posts made by these top users in both subreddits. Finally, we will present the findings in a bar chart.\n\n\n \n\nBusiness Goal - 5 : Determine the frequency and the accumulated scores of news sources. \n\nTechnical Proposal:  In this analysis, our objective is to comprehend the frequency and cumulative scores associated with different news sources. Initially, we’ll extract the “domain” information from the URL of each post. Subsequently, we’ll aggregate the data based on these sources, computing both the frequency of posts and summarizing the scores attributed to each source.",
    "crumbs": [
      "I. Overview",
      "Business Goals"
    ]
  },
  {
    "objectID": "goals.html#natural-language-processing-goals",
    "href": "goals.html#natural-language-processing-goals",
    "title": "Business Goals",
    "section": "",
    "text": "Business Goal - 6 : Determine the news topics that are interacted with the most.  Among all types of news, which category do people concern about the most? Is it related to war, disaster, food crisis or something else? \n\nTechnical Proposal: Use topic modeling to create different broad news categories. Group by those categories and analyze the comments.\n\n\n \n\nBusiness Goal - 7 : \nDetermine what topics are perceived as fake news. \n\nTechnical Proposal : Use topic modeling created above. Perform sentiment analysis on the comments. Comments with negative sentiment and containing misinformation identifiers will be misinformation. Topics with more of these comments will be perceived as fake news.\n\n\n \n\nBusiness Goal - 8 : \nFind this difference in perceived misinformation from 2021 (post-election year) to 2023 (pre-election year). \n\nTechnical Proposal : We will use the combined sentiment analysis and misinformation indicator to identify comments with negative sentiment and contain a misinformation indicator. We will group by this new variable and count the grouped data. Since there are significantly fewer comments in 2023, we will then take the rate of misinformation comments to compare the two.",
    "crumbs": [
      "I. Overview",
      "Business Goals"
    ]
  },
  {
    "objectID": "goals.html#machine-learning-goals",
    "href": "goals.html#machine-learning-goals",
    "title": "Business Goals",
    "section": "",
    "text": "Business Goal - 9 : \nWhich articles might be perceived as misinformation, or labeled by users as fake news? \n\nTechnical Proposal : We will employ a supervised machine learning model to predict articles that are prone to be perceived as misinformation. Specifically, we’ll utilize techniques such as decision trees to discern which features contribute significantly to the classification process. By analyzing various attributes of article titles, we’ll determine patterns indicating potential fake news. This comprehensive approach will shed light on both the types of titles more likely to be labeled as fake news and the key features crucial for classification accuracy.\n\n\n \n\nBusiness Goal - 10 : \nAmong political topics, is there any correlation? Are certain topics mentioned together more frequently than others?\n\nTechnical Proposal : We will conduct a network analysis to explore the relationships between different political topics. This analysis will help us understand the connections and interactions among various political themes, providing insights into how they are interconnected or influence each other within the broader political landscape.",
    "crumbs": [
      "I. Overview",
      "Business Goals"
    ]
  },
  {
    "objectID": "eda.html",
    "href": "eda.html",
    "title": "Exploratory Data Analysis",
    "section": "",
    "text": "We assessed the basic specifications of the dataset, removed duplicates and anomalies and dropped undesired columns to finally get 170,144 submissions and 18,548,934 comments in the respective datasets. The variables of interest after preprocessing the datasets are listed below:\nIn the  Submissions  dataset :\n\n\n\nauthor : The user who created the post.\n\n\ncreated_utc : The time the submission or comment was posted. Was used in the time series analysis section of our project.\n\n\ndomain : The news site posted in the submission.\n\n\nid : The unique identifier of each post.\n\n\nnum_comments : The number of comments under each submission. This may not capture the exact picture as it is dependent on the day the data was retrieved.\n\n\nurl : The url associated with the post. Most of the submissions contain this url to the news article.\n\n\nscore : The Karma score awarded to each post\n\n\nIn the  Comments  dataset :\n\n\n\nauthor : The user who posted the comment.\n\n\ncreated_utc : The time the submission or comment was posted. Was used in the time series analysis section of our project.\n\n\nbody : The text in the comment.\n\n\n id : The unique identifier of each comment.\n\n\nlink_id : The id of the submission under which the comment exists.\n\n\ncontroversiality : Whether a comment was classified as ‘controversial’.\n\n\n gilded : Whether the comments have been gilded or awarded.\n\n\n distinguished : Whether the comments have been distinguished as moderator.\n\n\n score : The Karma score awarded to each post\n\n\nDuring this process, several dummy variables were created to aid in our analysis. A foreign key like variable called submission_id was also created in the comments dataset, that linked any comment to the submission it was made under.",
    "crumbs": [
      "Exploratory Data Analysis",
      "Exploratory Data Analysis"
    ]
  },
  {
    "objectID": "eda.html#preprocessing-and-data-dictionary",
    "href": "eda.html#preprocessing-and-data-dictionary",
    "title": "Exploratory Data Analysis",
    "section": "",
    "text": "We assessed the basic specifications of the dataset, removed duplicates and anomalies and dropped undesired columns to finally get 170,144 submissions and 18,548,934 comments in the respective datasets. The variables of interest after preprocessing the datasets are listed below:\nIn the  Submissions  dataset :\n\n\n\nauthor : The user who created the post.\n\n\ncreated_utc : The time the submission or comment was posted. Was used in the time series analysis section of our project.\n\n\ndomain : The news site posted in the submission.\n\n\nid : The unique identifier of each post.\n\n\nnum_comments : The number of comments under each submission. This may not capture the exact picture as it is dependent on the day the data was retrieved.\n\n\nurl : The url associated with the post. Most of the submissions contain this url to the news article.\n\n\nscore : The Karma score awarded to each post\n\n\nIn the  Comments  dataset :\n\n\n\nauthor : The user who posted the comment.\n\n\ncreated_utc : The time the submission or comment was posted. Was used in the time series analysis section of our project.\n\n\nbody : The text in the comment.\n\n\n id : The unique identifier of each comment.\n\n\nlink_id : The id of the submission under which the comment exists.\n\n\ncontroversiality : Whether a comment was classified as ‘controversial’.\n\n\n gilded : Whether the comments have been gilded or awarded.\n\n\n distinguished : Whether the comments have been distinguished as moderator.\n\n\n score : The Karma score awarded to each post\n\n\nDuring this process, several dummy variables were created to aid in our analysis. A foreign key like variable called submission_id was also created in the comments dataset, that linked any comment to the submission it was made under.",
    "crumbs": [
      "Exploratory Data Analysis",
      "Exploratory Data Analysis"
    ]
  },
  {
    "objectID": "eda.html#analyzing-weekly-activity-trends",
    "href": "eda.html#analyzing-weekly-activity-trends",
    "title": "Exploratory Data Analysis",
    "section": "Analyzing Weekly Activity Trends",
    "text": "Analyzing Weekly Activity Trends\nIn this section, we delve into understanding the patterns of user engagement on Reddit. We begin by examining the distribution of activity across different days of the week, extracted from the DateTime variable. By grouping the data based on these days, we quantify the frequency of user interactions, both in terms of comments and submissions. The insights derived from this analysis are visually represented through a bar graph in Figure 2.1 and Figure 2.2.\n\n\n\n\n\n\n\n\n\n Figure 2.1: Number of submissions per day of the week from 2021-2023   As shown in Figure 2.1, the trend for submissions exhibits a significant dip during the weekends. This suggests that users are less likely to initiate new threads or topics on Saturday and Sunday.A potential factor contributing to this weekend slump could be the downtime in news cycles, as journalists and news outlets typically slow down on these days.Interestingly, Thursday is the busiest day for submissions, contrary to the intuitive expectation that Monday would start the week with a surge.\n\n\n\n\n\n\n\n\n\n Figure 2.2: Number of comments per day of the week from 2021-2023   Figure 2.2 depicts a different dynamic for comments, with activity gradually increasing from Monday, reaching a zenith on Thursday. This progressive increase could indicate users’ growing engagement with content as the week unfolds. Despite both submissions and comments peaking on Thursday, only comments display a steady climb throughout the weekdays.  When we synthesize the data from submissions and comments, a compelling narrative about user engagement emerges. Thursday stands out as a pinnacle of activity for Reddit, with both submissions and comments reaching their highest levels. This indicates that Thursdays are not just about new content being created but also about the peak in interactions with existing threads. The pattern across the week shows more engagement with ongoing discussions rather than starting new ones, especially as the week progresses.",
    "crumbs": [
      "Exploratory Data Analysis",
      "Exploratory Data Analysis"
    ]
  },
  {
    "objectID": "eda.html#analyzing-post-frequency-by-year",
    "href": "eda.html#analyzing-post-frequency-by-year",
    "title": "Exploratory Data Analysis",
    "section": "Analyzing Post Frequency by Year",
    "text": "Analyzing Post Frequency by Year\nIn this analysis, we investigate the disparity in the number of posts across different years. Utilizing the DateTime variable, we extract the year component to group the data accordingly. The findings are presented in two separate tables: Table 2.1 for submissions and Table 2.2 for comments.\n\n\n╒════════╤═════════╕\n│   year │   count │\n╞════════╪═════════╡\n│   2021 │  998335 │\n│   2022 │  732024 │\n│   2023 │  116779 │\n╘════════╧═════════╛\n\n\n Table 2.1: Submissions Per Year  \n\n\n╒════════╤══════════╕\n│   year │    count │\n╞════════╪══════════╡\n│   2022 │ 27272489 │\n│   2021 │ 19060400 │\n│   2023 │  3637011 │\n╘════════╧══════════╛\n\n\n Table 2.2: Comments Per Year   The analysis of post frequency by year reveals intriguing trends. While there is a notable decline in submissions from 2021 to 2023, the number of comments exhibits a contrasting pattern, with a significant increase observed from 2021 to 2022 followed by a decline in 2023. This divergence suggests a potential shift in user behavior towards increased engagement with existing content rather than generating new posts. Further investigation into the underlying factors influencing this trend could provide valuable insights into evolving user preferences and platform dynamics.\n  ## Assessing Percentage of Comments with Fake News Indicators\nTo evaluate the prevalence of fake news indicators in comments, we employed regex to detect phrases such as “fake news,” “bullshit,” or “propaganda.” Subsequently, a fake news indicator column was created to denote the presence of these phrases in comments. Grouping the data by this indicator column, we tallied the counts and visualized the findings in a chart. Among the total comments analyzed, 407,621 were flagged as containing fake news indicators, while the majority, comprising 49,562,279 comments, were deemed free from such indicators. This signifies that approximately 0.8% of comments were identified as potentially containing fake news elements. Further exploration into the context and implications of these comments could offer valuable insights into the dissemination of misinformation within online communities.\n\n\n\n\n\n\n\n\n\n Figure 2.3: Comments containing Misinformation Indicators from 2021-2023",
    "crumbs": [
      "Exploratory Data Analysis",
      "Exploratory Data Analysis"
    ]
  },
  {
    "objectID": "eda.html#analyzing-user-activity",
    "href": "eda.html#analyzing-user-activity",
    "title": "Exploratory Data Analysis",
    "section": "Analyzing User Activity",
    "text": "Analyzing User Activity\nAs we delve into the dynamics of user interactions within the news-centric communities on Reddit, we encounter some intriguing patterns. The subreddit under examination boasts 31.5 million subscribers. However, a closer inspection reveals that in the past year, approximately 27,000 unique users have made submissions, and around 1.2 million have commented.\nA minute fraction of these users contribute the bulk of the submissions, which is delineated in Figure 2.4. This chart illustrates a comparison of posting frequency among the top 10 users in both the News and World News subreddits. The disparity is stark; the top-ranked user alone is responsible for more than 60,000 submissions in the News subreddit, significantly overshadowing the rest.\n\n\n\n\n\n\n\n\n\n Figure 2.4: Top 10 Users Post Comparison for News and World News Subreddits   It was observed from the table above, that the most popular news sites on the subreddit over the past year were generally from western countries. This could potentially explain the high consumption of news related to the war within the subreddit despite the presence of Russian media sources as well.\nLive thread submissions were found and it was determined that all the live thread submissions pertained to the war. This provided an opportunity to evaluate the comments of the live thread against regular submissions that also dealt with the Conflict as shown in the table below.\n Table 2.3 : Comparison of Live Thread Comments and Regular Comments on War \nThe table above captures the percentage of comments that were controversial, gilded and distinguished for the live thread and for other submissions dealing with the war. It was observed that more controversiality was present in regular submissions as compared to live threads, possible due to larger number of normal posts.",
    "crumbs": [
      "Exploratory Data Analysis",
      "Exploratory Data Analysis"
    ]
  },
  {
    "objectID": "eda.html#most-common-words",
    "href": "eda.html#most-common-words",
    "title": "Exploratory Data Analysis",
    "section": "Most Common Words",
    "text": "Most Common Words\nProgressing with our analysis, we also looked at which were the most commonly used words or phrases in the comments of the top 3 news stories. To evaluate this we generated word clouds as shown below.\n\nFigure 2.6 : Word Cloud Of Comments From Top 3 News Stories\n\nThese word clouds revealed that the Russia-Ukraine Conflict , and political leaders of these countries were the most repeated words. We also found terms relating to Queen Elizabeth II’s demise and the British royal family to be quite repetitive.",
    "crumbs": [
      "Exploratory Data Analysis",
      "Exploratory Data Analysis"
    ]
  },
  {
    "objectID": "eda.html#comparison-with-other-sources",
    "href": "eda.html#comparison-with-other-sources",
    "title": "Exploratory Data Analysis",
    "section": "Comparison with Other Sources",
    "text": "Comparison with Other Sources\nAs a final task, we sought to compare the information present in the subreddit’s submissions about the events pertaining to Russia and Ukraine, with the events data from Armed Conflict Location & Event Data Project (ACLED). ACLED collects real-time data on locations, dates, actors, fatalities and types of all reported political violence and protest events around the world, from various international and regional news sources. The ACLED data for Ukraine and Russia were aggregated to obtain daily counts of event types in the following categories:\n\n\nArmed Clashes\n\n\nShelling/Artillery/Missile Attacks\n\n\nRemote Explosives/Landmines/IED\n\n\nDisrupted Weapons Use\n\n\nThe submissions titles were analyzed using regex to find terms related to aforementioned event types to obtain daily counts for these events. The cosine similarity between ACLED counts and counts obtained from submissions for each event type were found as shown below in table 2.4. Our results indicate that reddit data is not quite similar to ACLED data. One possible reason for low similarity might be that our data has been filtered to English, and ACLED uses its own translation methodology and produces regional level news related to the conflict as well.\n Table 2.4 : Cosine Similarity Scores for ACLED and Submissions Dataset on Different War Events",
    "crumbs": [
      "Exploratory Data Analysis",
      "Exploratory Data Analysis"
    ]
  },
  {
    "objectID": "results.html",
    "href": "results.html",
    "title": "Conclusion",
    "section": "",
    "text": "This project aimed to analyze the comments and posts on the r/worldnews subreddit through natural language processing (NLP) and machine learning (ML) techniques. In our Exploratory Data Analysis (EDA), we identified what news sites were primarily shared on the subreddit, via aggregated submission counts; began seeing what stories were most popular, based on karma scores; found that the discussion threads were heavily tied to the Russia-Ukraine Conflict; and examined the distribution of comments and submissions over time. We noted that several of the shared sites were American in origin, but also saw that many of the popular sources came from several European countries, including Russia. Other social media sites were also a popular submission choice, especially YouTube. Using the ACLED data, we were also able to determine that while the conflict was receiving a large share of attention, not all of the events of the conflict were being shared equally. Additionally, the time series analysis saw that there were multiple gaps in the dataset for certain time periods.\n Table 5.1 : Most Shared News Sites \nIn the NLP stage of our analysis, we chose to look closer at the topics and entities that the submissions were about, as well as examine the sentiment of both the comments and submissions. In our topic modelling we found that using the whole data resulted in groups with substantial amounts of overlap regarding the conflict. We then constrained the data to time periods that saw high amounts of search interest in Google Trends, creating two subsets which included posts and comments that occurred up to two weeks after the designated event’s date. The resulting subsetted data produced clearer topic groups, with specific events being highlighted, although the cluster of groups which were hard to differentiate remained. For the sentiment analysis at this stage, we used pretrained models from JohnSnowLabs to examine both the sentiment of the comments in the threads as well as comments and submission titles related to the Russia-Ukraine Conflict. Of the three different models used, Twitter and IMDB had identical results while the Vivek model registered a larger portion of the comments and submissions as neutral, but all three models indicated negative sentiment as the plurality of sentiments, if not the majority. The live threads’ results indicated strong sentiments, both positive and negative across the comments, a pattern which seemed to hold in the comments of submissions. The article titles, however, demonstrate much greater negativity according to the IMDB and Twitter models, while the Vivek model read it as again having more neutrality.\n Table 5.2 : Pre-Trained Models Sentiment Results on Comments and Submissions \nLastly, we have successfully designed and implemented predictive ML models to predict controversiality markers and the sentiment of comments and submissions. The controversiality model took in a TF-IDF weighted vector of the comments and was able to achieve a high level of predictive strength, although that seemed to be a result, in large part, due to the class imbalance. We believe that the deleted and removed comments were likely controversial, and so the remaining controversial ones were not being predicted as well as we would hope. For the sentiment model we decided to use Vader-Sentiment lexicon to label our data rather than relying exclusively on pretrained models. The dataset we used to classify sentiment appeared to label more similarly to the Vivek model, with the plurality being negative but showing a larger proportion of neutral material. Several ML algorithms were then used to train the labelled dataset and we ultimately saw great success with test error at slightly above 8%.\n Figure 5.1 : ROC Curves for Different Predictive Models Used in Predicting Controversiality \nMoving forward, we feel that we can further improve our models via the use of over and under sampling techniques to deal with the class imbalance. Additionally, we believe that we can improve on a predictive model for karma scores that we attempted, although at present its accuracy can be described only as pitiful."
  },
  {
    "objectID": "nlp.html",
    "href": "nlp.html",
    "title": "Natural Language Processing Analysis",
    "section": "",
    "text": "The data preprocessing pipeline involves several steps to prepare text data for topic modeling using LDA (Latent Dirichlet Allocation) and sentiment analysis in PySpark. Here’s a breakdown of the preprocessing steps: Here’s the description of the data preprocessing steps before applying the LDA model:\n\nText Cleaning:\n\nThe comments data is cleaned using a custom cleaning function, likely to remove noise, such as special characters, stopwords, and irrelevant content.\nAdditionally, potential typos are addressed by correcting typing errors and adding commonly occurring typos.\n\nIdentifying Misinformation:\n\nA column named ‘misinfo_class’ is added to the dataset, indicating whether the comment contains misinformation-related keywords such as “fake news,” “bullshit,” “propaganda,” etc.\n\nOtherPreparation:\n\nTokenization: The titles of the posts are tokenized using the Tokenizer.\nStopword Removal: Common English stopwords and additional irrelevant terms are removed using the StopWordsRemover class.\nCount Vectorization: The filtered tokens are converted into a numerical vector representation using the CountVectorizer class, limiting the vocabulary size to 5000 and considering only terms with a minimum document frequency of 25.\nInverse Document Frequency (IDF): IDF is applied to the count vectorized features to down-weight the importance of frequent terms.\n\n\nThese preprocessing steps prepare the data for topic modeling using LDA and the following sentiment analysis, ensuring that the text data is properly cleaned, transformed into a suitable format, and mapped to meaningful topics for analysis.",
    "crumbs": [
      "III. Natural Language Processing",
      "Natural Language Processing Analysis"
    ]
  },
  {
    "objectID": "nlp.html#text-pre-processing",
    "href": "nlp.html#text-pre-processing",
    "title": "Natural Language Processing Analysis",
    "section": "",
    "text": "The data preprocessing pipeline involves several steps to prepare text data for topic modeling using LDA (Latent Dirichlet Allocation) and sentiment analysis in PySpark. Here’s a breakdown of the preprocessing steps: Here’s the description of the data preprocessing steps before applying the LDA model:\n\nText Cleaning:\n\nThe comments data is cleaned using a custom cleaning function, likely to remove noise, such as special characters, stopwords, and irrelevant content.\nAdditionally, potential typos are addressed by correcting typing errors and adding commonly occurring typos.\n\nIdentifying Misinformation:\n\nA column named ‘misinfo_class’ is added to the dataset, indicating whether the comment contains misinformation-related keywords such as “fake news,” “bullshit,” “propaganda,” etc.\n\nOtherPreparation:\n\nTokenization: The titles of the posts are tokenized using the Tokenizer.\nStopword Removal: Common English stopwords and additional irrelevant terms are removed using the StopWordsRemover class.\nCount Vectorization: The filtered tokens are converted into a numerical vector representation using the CountVectorizer class, limiting the vocabulary size to 5000 and considering only terms with a minimum document frequency of 25.\nInverse Document Frequency (IDF): IDF is applied to the count vectorized features to down-weight the importance of frequent terms.\n\n\nThese preprocessing steps prepare the data for topic modeling using LDA and the following sentiment analysis, ensuring that the text data is properly cleaned, transformed into a suitable format, and mapped to meaningful topics for analysis.",
    "crumbs": [
      "III. Natural Language Processing",
      "Natural Language Processing Analysis"
    ]
  },
  {
    "objectID": "nlp.html#key-topics-in-submissions",
    "href": "nlp.html#key-topics-in-submissions",
    "title": "Natural Language Processing Analysis",
    "section": "Key Topics in Submissions",
    "text": "Key Topics in Submissions\nWe employed topic modeling through Latent Dirichlet Allocation (LDA) on the cleaned titles of our submissions dataset and obtained 8 topic groups, which covered various aspects of current affairs:\n\n\neconomics/russia&ukraine\n\n\nTop words: age, ukraine, new, height, indian, amp, crypto, russian, worth, wiki\n\n\n\n\npresidential news\n\n\nTop words: free, crack, u.s., key, biden, download, first, president, new, say\n\n\n\n\nsupreme court/law\n\n\nTop words: court, first, u.s., new, covid-19, covid, supreme, queen, cases\n\n\n\n\nglobal politics\n\n\nTop words: market, global, eu, china, industry, new, u.s., report, amp\n\n\n\n\nus politics\n\n\nTop words: best, u.s., biden, hong, president, review, 2022, trump\n\n\n\n\ncovid/russia&ukraine\n\n\nTop words: news, covid, covid-19, new, russia, russian, day, ukraine, china\n\n\n\n\ncrime/protest\n\n\nTop words: police, us, man, arrested, death, protests, trump, officer, years, murder\n\n\n\n\ntv shows\n\n\nTop words: episode, splitsvilla, mtv, show, full, getting, june\n\n\n\n\n\nFigure 3.1 : LDA Topic Visualization based on Title\n\n\n\n                                                \n\n\nLooking at Figure 3.1, almost half of the submissions relate to COVID-19, Russia/Ukraine, and crime/protest. Surprisingly, US politics is one of the smallest topic categories. This could be because many US news stories were more relevant to other categories like crime/ protest or presidential news.\n\nFigure 3.2 : Misinformation Counts by Topic\n\n\n\n                                                \n\n\n Looking at Figure 3.2, the two largest misinformation comment counts are COVID/Russia and Ukraine war and crime/protest. Both topics have about 90,000 misinformation comments. These are also the two largest categories, as we can see in Figure 3.4. The Supreme Court and Law topic has about 60,000 comments on misinformation. The TV show topic has the least amount od misinformation comments with almost 15,000.",
    "crumbs": [
      "III. Natural Language Processing",
      "Natural Language Processing Analysis"
    ]
  },
  {
    "objectID": "nlp.html#assessing-sentiments-on-comments",
    "href": "nlp.html#assessing-sentiments-on-comments",
    "title": "Natural Language Processing Analysis",
    "section": "Assessing Sentiments on Comments",
    "text": "Assessing Sentiments on Comments\nTo gain further insights into Reddit users’ attitudes toward different topics’ news, we employ sentiment analysis. VADER (Valence Aware Dictionary and sEntiment Reasoner) is utilized for this purpose. VADER is a rule-based sentiment analysis tool that evaluates the sentiment intensity of text. It operates by utilizing a pre-existing lexicon of words and linguistic rules to generate compound sentiment scores ranging from -1 to 1. Positive scores indicate positive sentiment, negative scores indicate negative sentiment, and scores around 0 denote neutrality.\nTo implement sentiment analysis using VADER, we leverage the SentimentIntensityAnalyzer class from the vaderSentiment library. We define a function called vader_sentiment, which accepts text input, computes its VADER score using the polarity_scores method of the analyzer, and returns the compound score.\n\nFigure 3.3 : Sentiment Intensity Frequency Across Vader Score Ranges\n\n\n\n                                                \n\n\nThe plot shows a declining trend from the interval [-1.0~-0.9] starting at just over 140,000, dropping sharply until the [0.8~-0.7] interval, then more gradually declining through the [0.7~-0.6] and [0.6~-0.5] intervals. There is a slight increase in frequency at the [0.5~-0.4] interval.\nThis distribution suggests that the most common sentiment scores in the analyzed dataset are strongly negative, as indicated by the higher counts in the negative score ranges. The presence of a minor increase in the last interval might suggest a small concentration of sentiments in that particular range as well.\n\nFigure 3.4 : Comparative Sentiment Distribution in Different News and Entertainment Sectors\n\n\n\n                                                \n\n\nIn Figure 3.4, we presents a set of four pie charts titled “Figure 3.4: Vader Score Distribution,” which illustrate the distribution of sentiment scores within four different categories: US politics, economics/Russia&Ukraine, presidential news, and TV shows. Each pie chart is divided into two segments based on a threshold value of -0.8 on the Vader sentiment scale.\nUS Politics: 60.3% of the sentiment scores are above -0.8, suggesting a more positive sentiment, while 39.7% are below -0.8, indicating a more negative sentiment. Economics/Russia&Ukraine: 61% of scores are above -0.8, and 39% are below -0.8, also showing a predominance of more positive sentiment. Presidential News: 59.4% of the scores are above -0.8, while 40.6% are below -0.8. TV Shows: 58.2% are above -0.8, and 41.8% are below -0.8. The color coding is consistent across all charts, with blue representing scores above -0.8 and pink representing scores below -0.8. In all categories, the majority of sentiments are above -0.8, indicating a leaning towards more positive or neutral sentiments overall. The similarity in the distribution across different categories suggests a possible pattern in the sentiment of the content analyzed, with none of the categories showing an overwhelming negative sentiment.",
    "crumbs": [
      "III. Natural Language Processing",
      "Natural Language Processing Analysis"
    ]
  },
  {
    "objectID": "ml.html",
    "href": "ml.html",
    "title": "Machine Learning Analysis",
    "section": "",
    "text": "For our Machine Learning (ML) we had two goals: to predict what articles would be percieved as misindotmation and to examine the network analysis between topics. We used logistic regression to predict if an article would be percieved as misinformation. We used the top 10 words in each topic as dummy variables to assist in our prediction. Though this did not lead to high accuracy, there were some interesting findings which we will detail below.",
    "crumbs": [
      "IV. Machine Learning",
      "Machine Learning Analysis"
    ]
  },
  {
    "objectID": "ml.html#executive-summary",
    "href": "ml.html#executive-summary",
    "title": "Machine Learning Analysis",
    "section": "",
    "text": "For our Machine Learning (ML) we had two goals: to predict what articles would be percieved as misindotmation and to examine the network analysis between topics. We used logistic regression to predict if an article would be percieved as misinformation. We used the top 10 words in each topic as dummy variables to assist in our prediction. Though this did not lead to high accuracy, there were some interesting findings which we will detail below.",
    "crumbs": [
      "IV. Machine Learning",
      "Machine Learning Analysis"
    ]
  },
  {
    "objectID": "ml.html#misinformation-article-prediction",
    "href": "ml.html#misinformation-article-prediction",
    "title": "Machine Learning Analysis",
    "section": "Misinformation article Prediction",
    "text": "Misinformation article Prediction\nWe used the following steps in our Logistic Regression model:\n\n\nGroup by article ID and get count of comments with misinformation indicators\n\n\nAny article with one or more misinformation indicators will be a perceived misinformation article\n\n\nMerge this dataframe with a dataframe containing the id, topic and title of the article\n\n\nDelete duplicates since the previous data frame was each row as a comment under article\n\n\nAdd dummy columns for top words in articles\n\n\nConvert label and topic columns to numerical representation\n\n\nCreate a vector for the topics column\n\n\nCreate a features vector containing the terms columns and topic column\n\n\nUse features vector in the logistic regression model\n\n  Table 4.1 : Articles with Misinformation Counts \n\n\n╒══════════════════════╤═════════╕\n│ label                │   count │\n╞══════════════════════╪═════════╡\n│ no perceived misinfo │  367441 │\n│ perceived misinfo    │   76555 │\n╘══════════════════════╧═════════╛\n\n\nTable 4.1 shows the original data frame with uneven classes. Since articles with misinformation comments were underrepresented, we decided to undersample the articles with no misinformation comments, resulting in the ratio shown in the next table.\n Table 4.2 : Undersampling Counts \n\n\n╒══════════════════════╤═════════╕\n│ label                │   count │\n╞══════════════════════╪═════════╡\n│ no perceived misinfo │   91922 │\n│ perceived misinfo    │   76555 │\n╘══════════════════════╧═════════╛\n\n\nTable 4.2 shows the sample from the entire dataset when undersampling the articles with no comments claiming misinformation. Here, we can see that the classes are almost equa, allowing us to proceed with the logistic regression. \nThe model had an accuracy of about 56% on the test data and 54% on the training dataset. The confusion matrix is shown below.\n Table 4.3 : Confusion Matrix \n\n\n\n\n\n\n\n\n\n Table 4.4 : Logistic Regression Table \n\n\n╒═══════════════════╤══════════════╤═══════════════╤══════════════════════════════════╤═════════════════════════════════════╤══════════════╤═════════════════════════════════════╕\n│ topic             │   true label │   false label │   incorrectly labeled as misinfo │   incorrectly labeled as no misinfo │   true ratio │   incorrectly labeled misinfo ratio │\n╞═══════════════════╪══════════════╪═══════════════╪══════════════════════════════════╪═════════════════════════════════════╪══════════════╪═════════════════════════════════════╡\n│ emerging tech     │        10128 │          7238 │                             1237 │                                6001 │     0.583209 │                            0.829096 │\n│ social media      │         8416 │          6519 │                             2918 │                                3601 │     0.563509 │                            0.552385 │\n│ current events    │         8745 │          6909 │                             3118 │                                3791 │     0.558643 │                            0.548705 │\n│ covid             │         7345 │          4668 │                              599 │                                4069 │     0.611421 │                            0.87168  │\n│ russia&ukraine    │        25208 │         19796 │                             4751 │                               15045 │     0.560128 │                            0.760002 │\n│ demographic info  │         3962 │          2823 │                              269 │                                2554 │     0.583935 │                            0.904711 │\n│ tv shows          │         3719 │          2196 │                              108 │                                2088 │     0.62874  │                            0.95082  │\n│ foriegn relations │         9750 │          7322 │                             1615 │                                5707 │     0.571111 │                            0.779432 │\n╘═══════════════════╧══════════════╧═══════════════╧══════════════════════════════════╧═════════════════════════════════════╧══════════════╧═════════════════════════════════════╛\n\n\nOverall, the model was not too accurate. The table below shows analysis by topic. We can see that the model was slightly more accurate at predicting perceived misinformation in COVID news and TV shows. It was slightly less accurate at predicting misinformation in current events. The final column shows the ratio of articles incorrectly labeled as containing no misinformation comments over the total number of falsely predicted articles. It basically shows the ratio of false negatives over false positives and false negatives. We can see the ratio is significantly higher for the topics: tv shows, demographic information, and covid. Foreign events and social media have the smallest ratio at about .55.",
    "crumbs": [
      "IV. Machine Learning",
      "Machine Learning Analysis"
    ]
  }
]